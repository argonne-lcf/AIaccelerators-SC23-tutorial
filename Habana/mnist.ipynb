{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch MNIST on Habana Gaudi 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the Hello Wolrd [PyTorch MNIST Example](https://github.com/HabanaAI/Model-References/tree/master/PyTorch/examples/computer_vision/hello_world ).\n",
    "For further information on training deep learning models using Gaudi, refer to [developer.habana.ai](https://developer.habana.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to MNIST Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "snippets"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/gaudi2_root/Model-References/PyTorch/examples/computer_vision/hello_world\n"
     ]
    }
   ],
   "source": [
    "%cd /root/gaudi2_root/Model-References/PyTorch/examples/computer_vision/hello_world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training Job\n",
    "\n",
    "This will run 1 HPU in FP32 Lazy Mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "snippets"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 1\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_CACHE_FOLDER_DELETE = 0\n",
      " PT_HPU_RECIPE_CACHE_CONFIG = \n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      "---------------------------: System Configuration :---------------------------\n",
      "Num CPU Cores : 160\n",
      "CPU RAM       : 1056389528 KB\n",
      "------------------------------------------------------------------------------\n",
      "Train Epoch: 1 [0/60000.0 (0%)]\tLoss: 2.295311\n",
      "Train Epoch: 1 [640/60000.0 (1%)]\tLoss: 2.085588\n",
      "Train Epoch: 1 [1280/60000.0 (2%)]\tLoss: 0.639452\n",
      "Train Epoch: 1 [1920/60000.0 (3%)]\tLoss: 0.487097\n",
      "Train Epoch: 1 [2560/60000.0 (4%)]\tLoss: 0.351031\n",
      "Train Epoch: 1 [3200/60000.0 (5%)]\tLoss: 0.389711\n",
      "Train Epoch: 1 [3840/60000.0 (6%)]\tLoss: 0.280259\n",
      "Train Epoch: 1 [4480/60000.0 (7%)]\tLoss: 0.393976\n",
      "Train Epoch: 1 [5120/60000.0 (9%)]\tLoss: 0.418906\n",
      "Train Epoch: 1 [5760/60000.0 (10%)]\tLoss: 0.139318\n",
      "Train Epoch: 1 [6400/60000.0 (11%)]\tLoss: 0.190440\n",
      "Train Epoch: 1 [7040/60000.0 (12%)]\tLoss: 0.204635\n",
      "Train Epoch: 1 [7680/60000.0 (13%)]\tLoss: 0.284255\n",
      "Train Epoch: 1 [8320/60000.0 (14%)]\tLoss: 0.147079\n",
      "Train Epoch: 1 [8960/60000.0 (15%)]\tLoss: 0.269709\n",
      "Train Epoch: 1 [9600/60000.0 (16%)]\tLoss: 0.198632\n",
      "Train Epoch: 1 [10240/60000.0 (17%)]\tLoss: 0.217296\n",
      "Train Epoch: 1 [10880/60000.0 (18%)]\tLoss: 0.145254\n",
      "Train Epoch: 1 [11520/60000.0 (19%)]\tLoss: 0.495754\n",
      "Train Epoch: 1 [12160/60000.0 (20%)]\tLoss: 0.152863\n",
      "Train Epoch: 1 [12800/60000.0 (21%)]\tLoss: 0.078689\n",
      "Train Epoch: 1 [13440/60000.0 (22%)]\tLoss: 0.159540\n",
      "Train Epoch: 1 [14080/60000.0 (23%)]\tLoss: 0.126993\n",
      "Train Epoch: 1 [14720/60000.0 (25%)]\tLoss: 0.274813\n",
      "Train Epoch: 1 [15360/60000.0 (26%)]\tLoss: 0.221386\n",
      "Train Epoch: 1 [16000/60000.0 (27%)]\tLoss: 0.124360\n",
      "Train Epoch: 1 [16640/60000.0 (28%)]\tLoss: 0.164414\n",
      "Train Epoch: 1 [17280/60000.0 (29%)]\tLoss: 0.066239\n",
      "Train Epoch: 1 [17920/60000.0 (30%)]\tLoss: 0.175449\n",
      "Train Epoch: 1 [18560/60000.0 (31%)]\tLoss: 0.073616\n",
      "Train Epoch: 1 [19200/60000.0 (32%)]\tLoss: 0.155532\n",
      "Train Epoch: 1 [19840/60000.0 (33%)]\tLoss: 0.156307\n",
      "Train Epoch: 1 [20480/60000.0 (34%)]\tLoss: 0.082932\n",
      "Train Epoch: 1 [21120/60000.0 (35%)]\tLoss: 0.235047\n",
      "Train Epoch: 1 [21760/60000.0 (36%)]\tLoss: 0.029257\n",
      "Train Epoch: 1 [22400/60000.0 (37%)]\tLoss: 0.033480\n",
      "Train Epoch: 1 [23040/60000.0 (38%)]\tLoss: 0.232805\n",
      "Train Epoch: 1 [23680/60000.0 (39%)]\tLoss: 0.208884\n",
      "Train Epoch: 1 [24320/60000.0 (41%)]\tLoss: 0.023836\n",
      "Train Epoch: 1 [24960/60000.0 (42%)]\tLoss: 0.068297\n",
      "Train Epoch: 1 [25600/60000.0 (43%)]\tLoss: 0.119461\n",
      "Train Epoch: 1 [26240/60000.0 (44%)]\tLoss: 0.093882\n",
      "Train Epoch: 1 [26880/60000.0 (45%)]\tLoss: 0.344983\n",
      "Train Epoch: 1 [27520/60000.0 (46%)]\tLoss: 0.182231\n",
      "Train Epoch: 1 [28160/60000.0 (47%)]\tLoss: 0.101252\n",
      "Train Epoch: 1 [28800/60000.0 (48%)]\tLoss: 0.154227\n",
      "Train Epoch: 1 [29440/60000.0 (49%)]\tLoss: 0.072097\n",
      "Train Epoch: 1 [30080/60000.0 (50%)]\tLoss: 0.142553\n",
      "Train Epoch: 1 [30720/60000.0 (51%)]\tLoss: 0.123276\n",
      "Train Epoch: 1 [31360/60000.0 (52%)]\tLoss: 0.087061\n",
      "Train Epoch: 1 [32000/60000.0 (53%)]\tLoss: 0.195067\n",
      "Train Epoch: 1 [32640/60000.0 (54%)]\tLoss: 0.143330\n",
      "Train Epoch: 1 [33280/60000.0 (55%)]\tLoss: 0.192936\n",
      "Train Epoch: 1 [33920/60000.0 (57%)]\tLoss: 0.035002\n",
      "Train Epoch: 1 [34560/60000.0 (58%)]\tLoss: 0.079217\n",
      "Train Epoch: 1 [35200/60000.0 (59%)]\tLoss: 0.125452\n",
      "Train Epoch: 1 [35840/60000.0 (60%)]\tLoss: 0.067779\n",
      "Train Epoch: 1 [36480/60000.0 (61%)]\tLoss: 0.080348\n",
      "Train Epoch: 1 [37120/60000.0 (62%)]\tLoss: 0.130769\n",
      "Train Epoch: 1 [37760/60000.0 (63%)]\tLoss: 0.095355\n",
      "Train Epoch: 1 [38400/60000.0 (64%)]\tLoss: 0.097694\n",
      "Train Epoch: 1 [39040/60000.0 (65%)]\tLoss: 0.017638\n",
      "Train Epoch: 1 [39680/60000.0 (66%)]\tLoss: 0.064209\n",
      "Train Epoch: 1 [40320/60000.0 (67%)]\tLoss: 0.022898\n",
      "Train Epoch: 1 [40960/60000.0 (68%)]\tLoss: 0.100662\n",
      "Train Epoch: 1 [41600/60000.0 (69%)]\tLoss: 0.044982\n",
      "Train Epoch: 1 [42240/60000.0 (70%)]\tLoss: 0.033715\n",
      "Train Epoch: 1 [42880/60000.0 (71%)]\tLoss: 0.130318\n",
      "Train Epoch: 1 [43520/60000.0 (72%)]\tLoss: 0.117686\n",
      "Train Epoch: 1 [44160/60000.0 (74%)]\tLoss: 0.023801\n",
      "Train Epoch: 1 [44800/60000.0 (75%)]\tLoss: 0.152588\n",
      "Train Epoch: 1 [45440/60000.0 (76%)]\tLoss: 0.119800\n",
      "Train Epoch: 1 [46080/60000.0 (77%)]\tLoss: 0.159038\n",
      "Train Epoch: 1 [46720/60000.0 (78%)]\tLoss: 0.191701\n",
      "Train Epoch: 1 [47360/60000.0 (79%)]\tLoss: 0.156146\n",
      "Train Epoch: 1 [48000/60000.0 (80%)]\tLoss: 0.054052\n",
      "Train Epoch: 1 [48640/60000.0 (81%)]\tLoss: 0.053859\n",
      "Train Epoch: 1 [49280/60000.0 (82%)]\tLoss: 0.026117\n",
      "Train Epoch: 1 [49920/60000.0 (83%)]\tLoss: 0.016731\n",
      "Train Epoch: 1 [50560/60000.0 (84%)]\tLoss: 0.131903\n",
      "Train Epoch: 1 [51200/60000.0 (85%)]\tLoss: 0.129519\n",
      "Train Epoch: 1 [51840/60000.0 (86%)]\tLoss: 0.036134\n",
      "Train Epoch: 1 [52480/60000.0 (87%)]\tLoss: 0.062272\n",
      "Train Epoch: 1 [53120/60000.0 (88%)]\tLoss: 0.097110\n",
      "Train Epoch: 1 [53760/60000.0 (90%)]\tLoss: 0.117088\n",
      "Train Epoch: 1 [54400/60000.0 (91%)]\tLoss: 0.041321\n",
      "Train Epoch: 1 [55040/60000.0 (92%)]\tLoss: 0.081631\n",
      "Train Epoch: 1 [55680/60000.0 (93%)]\tLoss: 0.127897\n",
      "Train Epoch: 1 [56320/60000.0 (94%)]\tLoss: 0.016230\n",
      "Train Epoch: 1 [56960/60000.0 (95%)]\tLoss: 0.102163\n",
      "Train Epoch: 1 [57600/60000.0 (96%)]\tLoss: 0.117081\n",
      "Train Epoch: 1 [58240/60000.0 (97%)]\tLoss: 0.004038\n",
      "Train Epoch: 1 [58880/60000.0 (98%)]\tLoss: 0.034756\n",
      "Train Epoch: 1 [59520/60000.0 (99%)]\tLoss: 0.002672\n",
      "\n",
      "Total test set: 10000, number of workers: 1\n",
      "* Average Acc 98.640 Average loss 0.043\n"
     ]
    }
   ],
   "source": [
    "!PT_HPU_LAZY_MODE=1 python mnist.py --batch-size=64 --epochs=1 --lr=1.0 --gamma=0.7 --hpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will run 1 HPU in BF16 lazy mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "snippets"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Habana Mixed Precision (HMP) module is deprecated and will be removed in version 1.13.0.\n",
      "Please use native PyTorch autocast for mixed precision training and inference\n",
      "hmp:verbose_mode  False\n",
      "hmp:opt_level O1\n",
      "Not using distributed mode\n",
      "============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 1\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_CACHE_FOLDER_DELETE = 0\n",
      " PT_HPU_RECIPE_CACHE_CONFIG = \n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      "---------------------------: System Configuration :---------------------------\n",
      "Num CPU Cores : 160\n",
      "CPU RAM       : 1056389528 KB\n",
      "------------------------------------------------------------------------------\n",
      "Train Epoch: 1 [0/60000.0 (0%)]\tLoss: 2.299363\n",
      "Train Epoch: 1 [640/60000.0 (1%)]\tLoss: 1.305269\n",
      "Train Epoch: 1 [1280/60000.0 (2%)]\tLoss: 0.790403\n",
      "Train Epoch: 1 [1920/60000.0 (3%)]\tLoss: 0.510326\n",
      "Train Epoch: 1 [2560/60000.0 (4%)]\tLoss: 0.334922\n",
      "Train Epoch: 1 [3200/60000.0 (5%)]\tLoss: 0.344155\n",
      "Train Epoch: 1 [3840/60000.0 (6%)]\tLoss: 0.169782\n",
      "Train Epoch: 1 [4480/60000.0 (7%)]\tLoss: 0.242249\n",
      "Train Epoch: 1 [5120/60000.0 (9%)]\tLoss: 0.268813\n",
      "Train Epoch: 1 [5760/60000.0 (10%)]\tLoss: 0.076916\n",
      "Train Epoch: 1 [6400/60000.0 (11%)]\tLoss: 0.310345\n",
      "Train Epoch: 1 [7040/60000.0 (12%)]\tLoss: 0.124946\n",
      "Train Epoch: 1 [7680/60000.0 (13%)]\tLoss: 0.221634\n",
      "Train Epoch: 1 [8320/60000.0 (14%)]\tLoss: 0.163268\n",
      "Train Epoch: 1 [8960/60000.0 (15%)]\tLoss: 0.234453\n",
      "Train Epoch: 1 [9600/60000.0 (16%)]\tLoss: 0.208241\n",
      "Train Epoch: 1 [10240/60000.0 (17%)]\tLoss: 0.465385\n",
      "Train Epoch: 1 [10880/60000.0 (18%)]\tLoss: 0.101253\n",
      "Train Epoch: 1 [11520/60000.0 (19%)]\tLoss: 0.456784\n",
      "Train Epoch: 1 [12160/60000.0 (20%)]\tLoss: 0.194197\n",
      "Train Epoch: 1 [12800/60000.0 (21%)]\tLoss: 0.129164\n",
      "Train Epoch: 1 [13440/60000.0 (22%)]\tLoss: 0.114922\n",
      "Train Epoch: 1 [14080/60000.0 (23%)]\tLoss: 0.136373\n",
      "Train Epoch: 1 [14720/60000.0 (25%)]\tLoss: 0.508519\n",
      "Train Epoch: 1 [15360/60000.0 (26%)]\tLoss: 0.069997\n",
      "Train Epoch: 1 [16000/60000.0 (27%)]\tLoss: 0.109958\n",
      "Train Epoch: 1 [16640/60000.0 (28%)]\tLoss: 0.159461\n",
      "Train Epoch: 1 [17280/60000.0 (29%)]\tLoss: 0.083362\n",
      "Train Epoch: 1 [17920/60000.0 (30%)]\tLoss: 0.091805\n",
      "Train Epoch: 1 [18560/60000.0 (31%)]\tLoss: 0.191574\n",
      "Train Epoch: 1 [19200/60000.0 (32%)]\tLoss: 0.156230\n",
      "Train Epoch: 1 [19840/60000.0 (33%)]\tLoss: 0.153503\n",
      "Train Epoch: 1 [20480/60000.0 (34%)]\tLoss: 0.036794\n",
      "Train Epoch: 1 [21120/60000.0 (35%)]\tLoss: 0.174706\n",
      "Train Epoch: 1 [21760/60000.0 (36%)]\tLoss: 0.041672\n",
      "Train Epoch: 1 [22400/60000.0 (37%)]\tLoss: 0.062481\n",
      "Train Epoch: 1 [23040/60000.0 (38%)]\tLoss: 0.096722\n",
      "Train Epoch: 1 [23680/60000.0 (39%)]\tLoss: 0.166322\n",
      "Train Epoch: 1 [24320/60000.0 (41%)]\tLoss: 0.048809\n",
      "Train Epoch: 1 [24960/60000.0 (42%)]\tLoss: 0.039838\n",
      "Train Epoch: 1 [25600/60000.0 (43%)]\tLoss: 0.049835\n",
      "Train Epoch: 1 [26240/60000.0 (44%)]\tLoss: 0.047867\n",
      "Train Epoch: 1 [26880/60000.0 (45%)]\tLoss: 0.154903\n",
      "Train Epoch: 1 [27520/60000.0 (46%)]\tLoss: 0.201127\n",
      "Train Epoch: 1 [28160/60000.0 (47%)]\tLoss: 0.167459\n",
      "Train Epoch: 1 [28800/60000.0 (48%)]\tLoss: 0.047843\n",
      "Train Epoch: 1 [29440/60000.0 (49%)]\tLoss: 0.079205\n",
      "Train Epoch: 1 [30080/60000.0 (50%)]\tLoss: 0.157721\n",
      "Train Epoch: 1 [30720/60000.0 (51%)]\tLoss: 0.081365\n",
      "Train Epoch: 1 [31360/60000.0 (52%)]\tLoss: 0.078515\n",
      "Train Epoch: 1 [32000/60000.0 (53%)]\tLoss: 0.049430\n",
      "Train Epoch: 1 [32640/60000.0 (54%)]\tLoss: 0.094992\n",
      "Train Epoch: 1 [33280/60000.0 (55%)]\tLoss: 0.079470\n",
      "Train Epoch: 1 [33920/60000.0 (57%)]\tLoss: 0.030524\n",
      "Train Epoch: 1 [34560/60000.0 (58%)]\tLoss: 0.123798\n",
      "Train Epoch: 1 [35200/60000.0 (59%)]\tLoss: 0.185876\n",
      "Train Epoch: 1 [35840/60000.0 (60%)]\tLoss: 0.059798\n",
      "Train Epoch: 1 [36480/60000.0 (61%)]\tLoss: 0.037611\n",
      "Train Epoch: 1 [37120/60000.0 (62%)]\tLoss: 0.071922\n",
      "Train Epoch: 1 [37760/60000.0 (63%)]\tLoss: 0.166812\n",
      "Train Epoch: 1 [38400/60000.0 (64%)]\tLoss: 0.084832\n",
      "Train Epoch: 1 [39040/60000.0 (65%)]\tLoss: 0.013294\n",
      "Train Epoch: 1 [39680/60000.0 (66%)]\tLoss: 0.032796\n",
      "Train Epoch: 1 [40320/60000.0 (67%)]\tLoss: 0.053168\n",
      "Train Epoch: 1 [40960/60000.0 (68%)]\tLoss: 0.193436\n",
      "Train Epoch: 1 [41600/60000.0 (69%)]\tLoss: 0.080676\n",
      "Train Epoch: 1 [42240/60000.0 (70%)]\tLoss: 0.028444\n",
      "Train Epoch: 1 [42880/60000.0 (71%)]\tLoss: 0.126691\n",
      "Train Epoch: 1 [43520/60000.0 (72%)]\tLoss: 0.110306\n",
      "Train Epoch: 1 [44160/60000.0 (74%)]\tLoss: 0.005662\n",
      "Train Epoch: 1 [44800/60000.0 (75%)]\tLoss: 0.128978\n",
      "Train Epoch: 1 [45440/60000.0 (76%)]\tLoss: 0.098568\n",
      "Train Epoch: 1 [46080/60000.0 (77%)]\tLoss: 0.228300\n",
      "Train Epoch: 1 [46720/60000.0 (78%)]\tLoss: 0.111121\n",
      "Train Epoch: 1 [47360/60000.0 (79%)]\tLoss: 0.072201\n",
      "Train Epoch: 1 [48000/60000.0 (80%)]\tLoss: 0.069438\n",
      "Train Epoch: 1 [48640/60000.0 (81%)]\tLoss: 0.025826\n",
      "Train Epoch: 1 [49280/60000.0 (82%)]\tLoss: 0.011006\n",
      "Train Epoch: 1 [49920/60000.0 (83%)]\tLoss: 0.080926\n",
      "Train Epoch: 1 [50560/60000.0 (84%)]\tLoss: 0.113093\n",
      "Train Epoch: 1 [51200/60000.0 (85%)]\tLoss: 0.132038\n",
      "Train Epoch: 1 [51840/60000.0 (86%)]\tLoss: 0.057616\n",
      "Train Epoch: 1 [52480/60000.0 (87%)]\tLoss: 0.008775\n",
      "Train Epoch: 1 [53120/60000.0 (88%)]\tLoss: 0.056811\n",
      "Train Epoch: 1 [53760/60000.0 (90%)]\tLoss: 0.144618\n",
      "Train Epoch: 1 [54400/60000.0 (91%)]\tLoss: 0.010724\n",
      "Train Epoch: 1 [55040/60000.0 (92%)]\tLoss: 0.029833\n",
      "Train Epoch: 1 [55680/60000.0 (93%)]\tLoss: 0.065278\n",
      "Train Epoch: 1 [56320/60000.0 (94%)]\tLoss: 0.049294\n",
      "Train Epoch: 1 [56960/60000.0 (95%)]\tLoss: 0.040306\n",
      "Train Epoch: 1 [57600/60000.0 (96%)]\tLoss: 0.094341\n",
      "Train Epoch: 1 [58240/60000.0 (97%)]\tLoss: 0.066459\n",
      "Train Epoch: 1 [58880/60000.0 (98%)]\tLoss: 0.011406\n",
      "Train Epoch: 1 [59520/60000.0 (99%)]\tLoss: 0.000424\n",
      "\n",
      "Total test set: 10000, number of workers: 1\n",
      "* Average Acc 98.630 Average loss 0.041\n"
     ]
    }
   ],
   "source": [
    "!PT_HPU_LAZY_MODE=1 python mnist.py --batch-size=64 --epochs=1 --lr=1.0 --gamma=0.7 --hpu --hmp --hmp-bf16=ops_bf16_mnist.txt --hmp-fp32=ops_fp32_mnist.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
